{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_models.chat_unsloth import ChatUnsloth\n",
    "\n",
    "llm = ChatUnsloth(model_path=\"pashaprokaz/qwen-7b-instruct-hotel-booking-4bit-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"val_data.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Current time: 2024-06-18 17:45:12 UTC (Tuesday)\n",
    "You are an assistant who can search and book a hotel for a user.\n",
    "Hotel search and reservations are made through the use of the following tools:\n",
    "\n",
    "search_hotels_tool(location: str, checkin_date: str, checkout_date: str, adults_number: int, children_number: int = 0, order_by: str = 'popularity', min_rating=None, min_price=None, max_price=None) -> List - Search for hotels in a given parameters.\n",
    "book_hotel_tool(id: int) -> str - Book hotel by a provided id. Id can be obtained from search_hotels_mock.\n",
    "\n",
    " Here is a list of possible parameters and their values:\n",
    "-location: str -> often just the name of the city\n",
    "-checkin_date: str -> format: YYYY-MM-DD\n",
    "-checkout_date: str -> format: YYYY-MM-DD\n",
    "-adults_number: int\n",
    "-children_number: int\n",
    "-min_rating: int -> must be in the range from 0 to 10\n",
    "-min_price: int\n",
    "-max_price: int\n",
    "-order_by: str -> possible values: popularity, price, rating\n",
    "-id: int -> it is used exclusively when booking, when the search has already been called\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "\n",
    "The `arguments` should be a dictionary, with keys corresponding to the argument names and the values corresponding to the requested values.\n",
    "If the user has not provided some important information, you still need to send a json blob.\n",
    "Don't make up the argument values yourself! Take only what the user specified!\n",
    "\n",
    "{user_input}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from utils import str_to_json\n",
    "\n",
    "results_finetuned = []\n",
    "for item in tqdm(val_data):\n",
    "    results_finetuned.append(llm.invoke(prompt.format(user_input=item['instruction'])))\n",
    "    results_finetuned[-1] = str_to_json(results_finetuned[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_results_qwen7b-hotel-instruct-v2.json', 'w') as f:\n",
    "    json.dump(results_finetuned, f, indent =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatUnsloth(model_path=\"unsloth/Qwen2-7B-Instruct-bnb-4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_qwen = []\n",
    "for item in tqdm(val_data):\n",
    "    results_qwen.append(llm.invoke(prompt.format(user_input=item['instruction'])))\n",
    "    results_qwen[-1] = str_to_json(results_qwen[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_results_qwen7b.json', 'w') as f:\n",
    "    json.dump(results_qwen, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import str_to_json\n",
    "\n",
    "qwen7b_results = json.load(open(\"val_results_qwen7b.json\", \"r\"))\n",
    "qwen7b_finetuned = json.load(open(\"val_results_qwen7b-hotel-instruct-v2.json\", \"r\"))\n",
    "val_data = json.load(open(\"val_data.json\", \"r\"))\n",
    "\n",
    "qwen7b_results_str = [str(d) for d in qwen7b_results]\n",
    "qwen7b_finetuned_str = [str(d) for d in qwen7b_finetuned]\n",
    "val_data_outputs = [d[\"output\"] for d in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, references):\n",
    "    from datasets import load_metric\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = load_metric(\"rouge\", trust_remote_code=True)\n",
    "    rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # BLEU\n",
    "    bleu = load_metric(\"bleu\", trust_remote_code=True)\n",
    "    references_bleu = [[ref.split()] for ref in references]\n",
    "    predictions_bleu = [pred.split() for pred in predictions]\n",
    "    bleu_result = bleu.compute(predictions=predictions_bleu, references=references_bleu)\n",
    "\n",
    "    # nulls (errors while parsing json blob)\n",
    "    nulls_count = sum([item == \"None\" for item in predictions])\n",
    "    nulls_ratio = nulls_count / len(predictions)\n",
    "\n",
    "    # precision on json arguments\n",
    "    predictions_jsons = [str_to_json(pred) for pred in predictions]\n",
    "    references_jsons = [str_to_json(ref) for ref in references]\n",
    "\n",
    "    precision_sum = 0\n",
    "    for pred, ref in zip(predictions_jsons, references_jsons):\n",
    "        current_precision = 0\n",
    "        if pred is not None and pred[\"name\"] == ref[\"name\"]:\n",
    "            for key in ref[\"arguments\"]:\n",
    "                if key in pred[\"arguments\"]:\n",
    "                    if pred[\"arguments\"][key] == ref[\"arguments\"][key]:\n",
    "                        current_precision += 1\n",
    "            precision_sum += current_precision / len(ref[\"arguments\"])\n",
    "    \n",
    "    precision__on_json = precision_sum / len(predictions_jsons)\n",
    "    \n",
    "\n",
    "    return {\"rouge\": rouge_result, \"bleu\": bleu_result, \"nulls\": {\"nulls_ratio\": nulls_ratio, \"nulls_count\": nulls_count}, \"precision__on_json\": precision__on_json}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 6.06kB [00:00, 12.1MB/s]                   \n",
      "Downloading extra modules: 4.07kB [00:00, 8.82MB/s]                   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.9314757949873719, recall=0.7869516898164721, fmeasure=0.8401867769029531), mid=Score(precision=0.9457516581142829, recall=0.8152974714404551, fmeasure=0.8624235833105862), high=Score(precision=0.9592311020044126, recall=0.8444324472442732, fmeasure=0.8825403598956094)),\n",
       "  'rouge2': AggregateScore(low=Score(precision=0.869927013173685, recall=0.745929342077654, fmeasure=0.7955970002657351), mid=Score(precision=0.8937775854449153, recall=0.7756688569481561, fmeasure=0.8194466193846981), high=Score(precision=0.9150814071478635, recall=0.80572531766845, fmeasure=0.8440823984054586)),\n",
       "  'rougeL': AggregateScore(low=Score(precision=0.912896708613124, recall=0.7697938592045381, fmeasure=0.8237513707290158), mid=Score(precision=0.929850303886506, recall=0.8013452328731068, fmeasure=0.8482072887920368), high=Score(precision=0.9451985923965911, recall=0.8279592537261158, fmeasure=0.8689162468450834)),\n",
       "  'rougeLsum': AggregateScore(low=Score(precision=0.9123762782747404, recall=0.7727372686952642, fmeasure=0.8251101365937136), mid=Score(precision=0.929935080874486, recall=0.8022367378959999, fmeasure=0.8485473905638197), high=Score(precision=0.9467316818088846, recall=0.8295921199604175, fmeasure=0.8682065239828284))},\n",
       " 'bleu': {'bleu': 0.6304313169837504,\n",
       "  'precisions': [0.8816837315130831,\n",
       "   0.7985257985257985,\n",
       "   0.7505003335557038,\n",
       "   0.7145985401459855],\n",
       "  'brevity_penalty': 0.8042370572664203,\n",
       "  'length_ratio': 0.8211116300794021,\n",
       "  'translation_length': 1758,\n",
       "  'reference_length': 2141},\n",
       " 'nulls': {'nulls_ratio': 0.007692307692307693, 'nulls_count': 1},\n",
       " 'precision__on_json': 0.6949420024420021}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(qwen7b_finetuned_str, val_data_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.8071773741279352, recall=0.7426246663940608, fmeasure=0.756527201325115), mid=Score(precision=0.8389705433466654, recall=0.7789693304690096, fmeasure=0.7887927278596703), high=Score(precision=0.8690185537697652, recall=0.8103621867618795, fmeasure=0.8175269270378688)),\n",
       "  'rouge2': AggregateScore(low=Score(precision=0.692019229679848, recall=0.6509876426333121, fmeasure=0.661182815737192), mid=Score(precision=0.7289221309555962, recall=0.6884418245087005, fmeasure=0.6965315432744363), high=Score(precision=0.7617281826261251, recall=0.7191282121571464, fmeasure=0.7254679296619316)),\n",
       "  'rougeL': AggregateScore(low=Score(precision=0.785782217974349, recall=0.7226537463419145, fmeasure=0.7352121357940978), mid=Score(precision=0.8212541943118195, recall=0.7596278721370863, fmeasure=0.7705980672034578), high=Score(precision=0.8524457948912171, recall=0.7922360431587748, fmeasure=0.8007684949960256)),\n",
       "  'rougeLsum': AggregateScore(low=Score(precision=0.7867907536723078, recall=0.7251803432582349, fmeasure=0.7381405420023635), mid=Score(precision=0.8215223169224743, recall=0.7589174191456405, fmeasure=0.770877241762469), high=Score(precision=0.8517541371287973, recall=0.7943185663129017, fmeasure=0.8033939376646719))},\n",
       " 'bleu': {'bleu': 0.4902981671118781,\n",
       "  'precisions': [0.7649234020073956,\n",
       "   0.5978445830969937,\n",
       "   0.5006105006105006,\n",
       "   0.426305353602115],\n",
       "  'brevity_penalty': 0.8772098966122779,\n",
       "  'length_ratio': 0.8841662774404484,\n",
       "  'translation_length': 1893,\n",
       "  'reference_length': 2141},\n",
       " 'nulls': {'nulls_ratio': 0.038461538461538464, 'nulls_count': 5},\n",
       " 'precision__on_json': 0.517851037851038}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(qwen7b_results_str, val_data_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mts-test-case-V9CDAOWC-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
